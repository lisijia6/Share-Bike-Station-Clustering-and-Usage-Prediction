{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23736,"status":"ok","timestamp":1648791896614,"user":{"displayName":"Nancy Li","userId":"12562624317552008542"},"user_tz":240},"id":"MxQSFhZ_Q8yn","outputId":"084929d6-bb81-4d3c-c33b-2668adcf8f35"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N2KuwBtUQwRH"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","import holidays\n","import itertools\n","from sklearn.linear_model import LinearRegression, Ridge\n","# from sklearn.preprocessing import OneHotEncoder\n","from sklearn.metrics import mean_squared_error, max_error, mean_absolute_error\n","import time"]},{"cell_type":"markdown","metadata":{"id":"FvkpXACgReNS"},"source":["# 1. Import Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FT63DrCLOagM"},"outputs":[],"source":["def import_ridership_weather_data():\n","  # Import ridership data\n","  data_dir = '/content/drive/My Drive/MIE498 Thesis/0_Data'\n","  merged_bike_data_2019 = pd.read_csv(\"{}/ridership_2019_with_bike_stations_info_20200930.csv\".format(data_dir), header=0)\n","  print(merged_bike_data_2019.shape)\n","  merged_bike_data_2019['End Day of Year'] = merged_bike_data_2019.apply(lambda row: datetime.strptime(row['End Time'], \"%Y-%m-%d %H:%M:%S\").timetuple().tm_yday, axis=1)\n","  print(merged_bike_data_2019.shape)\n","\n","  merged_bike_data_2019['Start Time'] = merged_bike_data_2019.apply(lambda row: datetime.strptime(row['Start Time'], \"%Y-%m-%d %H:%M:%S\"), axis=1)\n","  merged_bike_data_2019['Start Day'] = merged_bike_data_2019.apply(lambda row: row['Start Time'].day, axis=1)\n","  merged_bike_data_2019['End Time'] = merged_bike_data_2019.apply(lambda row: datetime.strptime(row['End Time'], \"%Y-%m-%d %H:%M:%S\"), axis=1)\n","  merged_bike_data_2019['End Day'] = merged_bike_data_2019.apply(lambda row: row['End Time'].day, axis=1)\n","\n","  # Import weather data\n","  df_weather = pd.read_csv('/content/drive/My Drive/MIE498 Thesis/Share-Bike-Station-Clustering-and-Usage-Prediction/toronto_weather_2019.csv', index_col=None)\n","  df_weather['Month'] = df_weather['Month'].astype(\"float64\")\n","  df_weather['Day'] = df_weather['Day'].astype(\"float64\")\n","  df_weather['Hour'] = df_weather['Hour'].astype(\"float64\")\n","  df_weather['Day of Week'] = df_weather['Day of Week'].astype(\"float64\")\n","\n","  return merged_bike_data_2019, df_weather"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YfmkYT8-NalX"},"outputs":[],"source":["def merge_clustering_data(ridership_data, weather_data):\n","  merged_data = merged_bike_data_2019.copy()\n","  # Import cluster-station-assignment data\n","  df_data_w_clusters = pd.read_csv('/content/drive/My Drive/MIE498 Thesis/0_Data/station_assignment.csv', header=0, encoding='ISO-8859-1')\n","  fsa_list = list(df_data_w_clusters['FSA_code'].unique())\n","  cluster_list = list(np.arange(38))\n","  fsa_to_cluster_dict = {fsa_list[i]: cluster_list[i] for i in range(len(fsa_list))}\n","  df_data_w_clusters['cluster'] = df_data_w_clusters.apply(lambda row: fsa_to_cluster_dict.get(row['FSA_code']), axis=1)\n","\n","  merged_data = merged_data.merge(df_data_w_clusters[['station_id', 'cluster']], how='left', left_on='Start Station Id', right_on='station_id').drop('station_id', axis=1)\n","  merged_data.rename({'cluster': 'Start Cluster'}, axis=1, inplace=True)\n","  merged_data = merged_data.merge(df_data_w_clusters[['station_id', 'cluster']], how='left', left_on='End Station Id', right_on='station_id').drop('station_id', axis=1)\n","  merged_data.rename({'cluster': 'End Cluster'}, axis=1, inplace=True)\n","\n","  merged_data = merged_data.merge(df_weather[['Month', 'Day', 'Hour', 'Temperature (Celsius)']], how='left', left_on=['Start Month', 'Start Day', 'Start Hour'], right_on=['Month', 'Day', 'Hour']).drop(['Month', 'Day', 'Hour'], axis=1)\n","  merged_data.rename({'Temperature (Celsius)': 'Start Temp'}, axis=1, inplace=True)\n","  merged_data = merged_data.merge(df_weather[['Month', 'Day', 'Hour', 'Temperature (Celsius)']], how='left', left_on=['End Month', 'End Day', 'End Hour'], right_on=['Month', 'Day', 'Hour']).drop(['Month', 'Day', 'Hour'], axis=1)\n","  merged_data.rename({'Temperature (Celsius)': 'End Temp'}, axis=1, inplace=True)\n","\n","  return merged_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_aZftvoPaY8"},"outputs":[],"source":["def check_weekend(dayofweek):\n","    if dayofweek > 4:\n","      return 'weekend'\n","    else:\n","      return 'weekday'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1OG7xTIYTe5H"},"outputs":[],"source":["def filter_checkout_checkin_data(merged_data):\n","# check-out and check-in data split\n","  checkout_data = merged_data[['Trip Id', 'Start Station Id', 'Start Time', 'Start Station Name', 'Start Year', 'Start Month', 'Start Hour',\n","        'Start Day of Week', 'Start Holiday', 'Start Day of Year', 'Start Week of Year', 'Start Lat', 'Start Lon', 'Start Cluster', 'Start Temp']]\n","  checkout_data['weekday/weekend'] = checkout_data.apply(lambda row: check_weekend(row['Start Day of Week']), axis=1)\n","\n","  checkin_data = merged_data[['Trip Id', 'End Station Id', 'End Time', 'End Station Name', 'End Year', 'End Month',\n","        'End Hour', 'End Day of Week', 'End Holiday', 'End Lat', 'End Lon', 'End Day of Year', 'End Cluster', 'End Temp']]\n","  checkin_data['weekday/weekend'] = checkin_data.apply(lambda row: check_weekend(row['End Day of Week']), axis=1)\n","\n","  return checkout_data, checkin_data"]},{"cell_type":"markdown","metadata":{"id":"oLfwYOlXTIvl"},"source":["# 2. Class Definition"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vzxfoyWIipgd"},"outputs":[],"source":["class BikeDemand:\n","  def __init__(self, nTransitions, tempflag):\n","    self.nTransitionMatrix = nTransitions\n","    self.tempFlag = tempflag\n","    self.nClusters = None\n","\n","  # Training: Months 1-9, Testing: Months 10-12\n","  def train_test_split(self, data, start_end_flag):\n","    training_data = data.loc[(data['{} Month'.format(start_end_flag)] >= 1) & (data['{} Month'.format(start_end_flag)] <= 9)]\n","    testing_data = data.loc[(data['{} Month'.format(start_end_flag)] >= 10) & (data['{} Month'.format(start_end_flag)] <= 12)]\n","    print(data.shape, training_data.shape, testing_data.shape)\n","    return training_data, testing_data\n","  \n","  def fill_in_missing_combinations(self, data, start_end_flag):\n","    # Check missing combinations\n","    \n","    hours = np.arange(24)\n","    # dayofyear = data['{} Day of Year'.format(start_end_flag)].unique()\n","    weekday_weekend = ['weekday', 'weekend']\n","    clusters = np.arange(self.nClusters)\n","\n","    combinations = itertools.product(hours, weekday_weekend, clusters)\n","    features_list = ['{} Hour'.format(start_end_flag), 'weekday/weekend', '{} Cluster'.format(start_end_flag)]\n","    df_combinations = data[features_list].to_numpy().astype('str')\n","    df_combinations = df_combinations.tolist()\n","    comb_list = []\n","    for comb in combinations:\n","      comb = [str(comb[0]), comb[1], str(comb[2])]\n","      if comb not in df_combinations:\n","        # print(comb)\n","        comb_list.append(comb)\n","    print('number of missing combinations:', len(comb_list))\n","\n","    # Fill in missing combinations\n","    for comb in comb_list:\n","      hour = int(comb[0])\n","      weekday_weekend = comb[1]\n","      cluster = int(comb[2])\n","      df_select = data[(data['{} Hour'.format(start_end_flag)] == hour) & (data['weekday/weekend'] == weekday_weekend)]\n","      \n","      clusters_list = data['{} Cluster'.format(start_end_flag)].unique()\n","      for c in clusters:\n","        if c not in clusters_list:\n","          if self.tempFlag == True:\n","            for temperature in df_select['{} Temp'.format(start_end_flag)].unique():\n","              for doy in df_select[df_select['{} Temp'.format(start_end_flag)] == temperature]['{} Day of Year'.format(start_end_flag)].unique():\n","                new_row = {'{} Hour'.format(start_end_flag) : hour, 'weekday/weekend' : weekday_weekend, \n","                            '{} Cluster'.format(start_end_flag) : cluster, '{} Day of Year'.format(start_end_flag) : doy,\n","                            '{} Temp'.format(start_end_flag) : temperature, 'Trip Id': 0.000001}\n","                data = data.append(new_row, ignore_index = True)\n","          else:\n","            for doy in df_select['{} Day of Year'.format(start_end_flag)].unique():\n","                new_row = {'{} Hour'.format(start_end_flag) : hour, 'weekday/weekend' : weekday_weekend, \n","                            '{} Cluster'.format(start_end_flag) : cluster, '{} Day of Year'.format(start_end_flag) : doy,\n","                            'Trip Id': 0.000001}\n","                data = data.append(new_row, ignore_index = True)\n","    return data\n","  \n","  def preprocess_data(self, train_data, test_data, start_end_flag):\n","    features_list = ['Trip Id', '{} Hour'.format(start_end_flag), 'weekday/weekend', '{} Cluster'.format(start_end_flag), '{} Day of Year'.format(start_end_flag)]\n","    grouping_features_list = ['{} Hour'.format(start_end_flag), 'weekday/weekend', '{} Cluster'.format(start_end_flag), '{} Day of Year'.format(start_end_flag)]\n","    reset_levels_list = [0,1,2,3]\n","    if self.tempFlag == True:\n","      features_list += ['{} Temp'.format(start_end_flag)]\n","      grouping_features_list += ['{} Temp'.format(start_end_flag)]\n","      reset_levels_list += [4]\n","    train_data = train_data[features_list]\n","    train_data = train_data.groupby(by=grouping_features_list).count()\n","    # print(train_data.head())\n","    train_data = train_data.reset_index(level=reset_levels_list)\n","    train_data['{} Hour'.format(start_end_flag)] = train_data['{} Hour'.format(start_end_flag)].astype(\"int64\")\n","\n","    test_data = test_data[features_list]\n","    test_data = test_data.groupby(by=grouping_features_list).count()\n","    test_data = test_data.reset_index(level=reset_levels_list)\n","    test_data['{} Hour'.format(start_end_flag)] = test_data['{} Hour'.format(start_end_flag)].astype(\"int64\")\n","\n","    train_data = self.fill_in_missing_combinations(train_data, start_end_flag)\n","    test_data = self.fill_in_missing_combinations(test_data, start_end_flag)\n","\n","    if start_end_flag == 'Start':\n","      name = 'Number of Checkouts'\n","    else:\n","      name = 'Number of Checkins'\n","\n","    train_data = train_data.sort_values(by=grouping_features_list)\n","    train_data.rename({'Trip Id': name}, axis=1, inplace=True)\n","    train_data.reset_index(drop=True, inplace=True)\n","\n","    test_data = test_data.sort_values(by=grouping_features_list)\n","    test_data.rename({'Trip Id': name}, axis=1, inplace=True)\n","    test_data.reset_index(drop=True, inplace=True)\n","\n","    print('Train Data Shape: ', train_data.shape)\n","    print('Test Data Shape: ', test_data.shape)\n","\n","    return train_data, test_data\n","\n","  def predict_checkout(self, checkout_train, checkout_test):\n","    features_list = ['Start Hour', 'weekday/weekend', 'Start Cluster']\n","    if self.tempFlag == True:\n","      features_list += ['Start Temp']\n","    X_train = checkout_train[features_list]\n","    X_train = pd.get_dummies(data=X_train, columns=['Start Hour', 'weekday/weekend', 'Start Cluster'], drop_first=True).to_numpy()\n","    y_train = checkout_train[['Number of Checkouts']].to_numpy()\n","\n","    X_test = checkout_test[features_list]\n","    X_test = pd.get_dummies(data=X_test, columns=['Start Hour', 'weekday/weekend', 'Start Cluster'], drop_first=True).to_numpy()\n","    y_test = checkout_test[['Number of Checkouts']].to_numpy()\n","\n","    y_train_log, y_test_log = np.log(y_train), np.log(y_test)\n","    checkout_linreg = LinearRegression().fit(X_train, y_train_log)\n","\n","    y_train_pred = np.exp(checkout_linreg.predict(X_train))\n","    y_test_pred = np.exp(checkout_linreg.predict(X_test))\n","\n","    return X_train, y_train, y_train_pred, X_test, y_test, y_test_pred\n","  \n","  def evaluate(self, y_true, y_pred):\n","    mse = round(mean_squared_error(y_true, y_pred, squared=True),3) # MSE\n","    rmse = round(mean_squared_error(y_true, y_pred, squared=False),3) # RMSE\n","    mre = round(max_error(y_true, y_pred),3) # maximum residual error\n","    mae = round(mean_absolute_error(y_true, y_pred),3) # MAE\n","    # r2 = round(r2_score(y_true, y_pred),3)\n","    # return mse, rmse, mre, mae, r2\n","    return mse, rmse, mre, mae\n","\n","  def generate_transition_matrix(self, df_train_select):\n","    from_cluster_list = list(np.arange(0, self.nClusters))\n","    df_transition_matrix = pd.DataFrame(data=np.zeros((self.nClusters, self.nClusters)), columns = from_cluster_list, index=from_cluster_list)\n","    df_transition_matrix = df_transition_matrix.astype(\"int\")\n","\n","    for from_cluster in from_cluster_list:\n","      data_train_temp = df_train_select[df_train_select['Start Cluster'] == from_cluster]\n","      df_counts = pd.DataFrame(data_train_temp['End Cluster'].value_counts())\n","      \n","      # print(df_counts.head())\n","      to_cluster_list = list(df_counts.index)\n","      \n","      for to_cluster in to_cluster_list:\n","        cnt = df_counts.loc[to_cluster]['End Cluster']\n","        df_transition_matrix.loc[from_cluster, to_cluster] = cnt\n","      \n","      df_transition_matrix = df_transition_matrix.div(df_transition_matrix.sum(axis=1), axis=0)\n","\n","    df_transition_matrix.replace(np.nan, 0, inplace=True)\n","    return df_transition_matrix\n","  \n","  def generate_transition_matrix_dict(self, data_train):\n","    n = self.nTransitionMatrix\n","    transition_matrix_dict = {}\n","    if n == 1:\n","      return self.generate_transition_matrix(data_train)\n","    \n","    elif n == 24:\n","      for hr in data_train['Start Hour'].unique():\n","        df_train_select = data_train[data_train['Start Hour'] == hr]\n","        transition_matrix = self.generate_transition_matrix(df_train_select)\n","        transition_matrix_dict[hr] = transition_matrix\n","      return transition_matrix_dict\n","    \n","    elif n == 48:\n","      for hr in data_train['Start Hour'].unique():\n","        for wd in data_train['weekday/weekend'].unique():\n","          df_train_select = data_train[(data_train['Start Hour'] == hr) & (data_train['weekday/weekend'] == wd)]\n","          transition_matrix = self.generate_transition_matrix(df_train_select)\n","          transition_matrix_dict[(hr, wd)] = transition_matrix\n","      return transition_matrix_dict\n","  \n","  def predict_checkin_by_cluster(self, df_predictions, df_transition_matrix):\n","    checkin_prediction_list = []\n","    columns_list = ['End Cluster {}'.format(c) for c in np.arange(self.nClusters)]\n","    df_checkin = pd.DataFrame(columns = columns_list)\n","\n","    if self.nTransitionMatrix == 1:\n","      for idx, row in df_predictions.iterrows():\n","        if idx % 5000 == 0:\n","          print(idx)\n","        checkout_prediction = row['Check-out Predictions']\n","        cluster_n = row['Start Cluster']\n","        transition_list = np.array(df_transition_matrix.iloc[cluster_n])\n","        # check-out predictions x transition matrix = check-in predictions\n","        checkin_prediction = np.round(transition_list * checkout_prediction, 6)\n","        checkin_prediction = pd.Series(checkin_prediction, index = df_checkin.columns)\n","        df_checkin = df_checkin.append(checkin_prediction, ignore_index=True)\n","    elif self.nTransitionMatrix == 24:\n","      for idx, row in df_predictions.iterrows():\n","        if idx % 5000 == 0:\n","          print(idx)\n","        checkout_prediction = row['Check-out Predictions']\n","        cluster_n = row['Start Cluster']\n","        hour = row['Start Hour']\n","        transition_list = np.array(df_transition_matrix[hour].iloc[cluster_n])\n","        # check-out predictions x transition matrix = check-in predictions\n","        checkin_prediction = np.round(transition_list * checkout_prediction, 6)\n","        checkin_prediction = pd.Series(checkin_prediction, index = df_checkin.columns)\n","        df_checkin = df_checkin.append(checkin_prediction, ignore_index=True)\n","    elif self.nTransitionMatrix == 48:\n","      for idx, row in df_predictions.iterrows():\n","        if idx % 5000 == 0:\n","          print(idx)\n","        checkout_prediction = row['Check-out Predictions']\n","        cluster_n = row['Start Cluster']\n","        hour, weekday = row['Start Hour'], row['weekday/weekend']\n","        transition_list = np.array(df_transition_matrix[(hour, weekday)].iloc[cluster_n])\n","        # check-out predictions x transition matrix = check-in predictions\n","        checkin_prediction = np.round(transition_list * checkout_prediction, 6)\n","        checkin_prediction = pd.Series(checkin_prediction, index = df_checkin.columns)\n","        df_checkin = df_checkin.append(checkin_prediction, ignore_index=True)\n","    \n","    return pd.concat([df_predictions, df_checkin], axis=1)\n","  \n","  def compute_true_checkin(self, checkin_test):\n","    features_list = ['End Hour', 'weekday/weekend', 'End Day of Year']\n","    data_columns = ['End Hour','weekday/weekend', 'End Cluster', 'Number of Checkins']\n","    if self.tempFlag == True:\n","      features_list += ['End Temp']\n","      data_columns += ['End Temp']\n","    df = checkin_test[features_list].drop_duplicates()\n","    clusters = np.arange(self.nClusters)\n","    df_checkin = pd.DataFrame(columns = data_columns)\n","    for idx, row in df.iterrows():\n","      if self.tempFlag == True:\n","        hr, wd, edoy, temp = row[0], row[1], row[2], row[3]\n","        df_temp = checkin_test[(checkin_test['End Hour'] == hr) & (checkin_test['weekday/weekend'] == wd) & \n","                             (checkin_test['End Day of Year'] == edoy) & (checkin_test['End Temp'] == temp)]\n","      else: \n","        hr, wd, edoy = row[0], row[1], row[2]\n","        df_temp = checkin_test[(checkin_test['End Hour'] == hr) & (checkin_test['weekday/weekend'] == wd) & \n","                             (checkin_test['End Day of Year'] == edoy)]\n","      \n","      clusters_list = df_temp['End Cluster'].unique()\n","      for c in clusters:\n","        if c not in clusters_list:\n","          if self.tempFlag == True:\n","            new_row = {'End Hour' : hr, 'weekday/weekend' : wd, 'End Cluster' : c, 'End Day of Year' : edoy, 'End Temp' : temp, 'Number of Checkins': 0.000001}\n","          else:\n","            new_row = {'End Hour' : hr, 'weekday/weekend' : wd, 'End Cluster' : c, 'End Day of Year' : edoy, 'Number of Checkins': 0.000001}\n","          df_temp = df_temp.append(new_row, ignore_index = True)\n","      if self.tempFlag == True:\n","        df_temp.sort_values(by=['End Hour', 'weekday/weekend', 'End Cluster', 'End Day of Year', 'End Temp'], inplace=True)\n","      else:\n","        df_temp.sort_values(by=['End Hour', 'weekday/weekend', 'End Cluster', 'End Day of Year'], inplace=True)\n","      df_temp.reset_index(drop=True, inplace=True)\n","      if len(df_temp) != self.nClusters:\n","        print(df_temp)\n","      df_checkin = df_checkin.append(df_temp, ignore_index = True)\n","        \n","    return df_checkin\n","  \n","  def run_prediction_pipeline(self, merged_data, checkout_data, checkin_data):\n","    self.nClusters = len(merged_data['Start Cluster'].unique())\n","    print(self.nClusters)\n","\n","    print('Checkout predictions')\n","    checkout_train, checkout_test = self.train_test_split(checkout_data, 'Start')\n","    checkout_train, checkout_test = self.preprocess_data(checkout_train, checkout_test, 'Start')\n","    X_train, y_train, y_train_pred, X_test, y_test, y_test_pred = self.predict_checkout(checkout_train, checkout_test)\n","\n","    print('Checkout training and testing errors')\n","    mse_train, rmse_train, mre_train, mae_train = self.evaluate(y_train, y_train_pred)\n","    mse_test, rmse_test, mre_test, mae_test = self.evaluate(y_test, y_test_pred)\n","    print('training errors: ', mse_train, rmse_train, mre_train, mae_train)\n","    print('testing errors: ', mse_test, rmse_test, mre_test, mae_test)\n","\n","    print('Transition Matrix Computation')\n","    data_train, data_test = self.train_test_split(merged_data, 'Start')\n","    data_train['weekday/weekend'] = data_train.apply(lambda row: check_weekend(row['Start Day of Week']), axis=1)\n","    df_transition_matrix = self.generate_transition_matrix_dict(data_train)\n","\n","    print('Summarize checkout predictions')\n","    if self.tempFlag == True:\n","      df_predictions = checkout_test[['Start Hour', 'weekday/weekend', 'Start Cluster', 'Start Temp']]\n","    else:\n","      df_predictions = checkout_test[['Start Hour', 'weekday/weekend', 'Start Cluster']]\n","    df_predictions['Check-out Predictions'], df_predictions['Check-out True Values'] = y_test_pred, y_test\n","    df_predictions = self.predict_checkin_by_cluster(df_predictions, df_transition_matrix)\n","\n","    print('Checkin predictions')\n","    checkin_train, checkin_test = self.train_test_split(checkin_data, 'End')\n","    checkin_train, checkin_test = self.preprocess_data(checkin_train, checkin_test, 'End')\n","    df_checkin = self.compute_true_checkin(checkin_test)\n","    checkin_pred = []\n","    \n","    if self.tempFlag == True:\n","      df_checkin_row = df_checkin[['End Hour', 'weekday/weekend', 'End Temp', 'End Day of Year']].drop_duplicates()\n","    else:\n","      df_checkin_row = df_checkin[['End Hour', 'weekday/weekend', 'End Day of Year']].drop_duplicates()\n","      df_predictions2_cp = df_predictions.copy()\n","      df_predictions2_cp.drop(columns=['Check-out True Values'], inplace=True)\n","      df_predictions2_cp = df_predictions2_cp.drop_duplicates()\n","    \n","    for idx, row in df_checkin_row.iterrows():\n","      if self.tempFlag == True:\n","        hr, wd, temp = row[0], row[1], row[2]\n","        temp_pred_list = df_predictions[(df_predictions['Start Hour'] == hr) & (df_predictions['weekday/weekend'] == wd) & (df_predictions['Start Temp'] == temp)].iloc[:, 6:].sum(axis=0)\n","      else:\n","        hr, wd = row[0], row[1]\n","        temp_pred_list = df_predictions2_cp[(df_predictions['Start Hour'] == hr) & (df_predictions2_cp['weekday/weekend'] == wd)].iloc[:, 4:].sum(axis=0)\n","      \n","      if len(temp_pred_list) != self.nClusters:\n","        print(len(temp_pred_list))\n","      checkin_pred += temp_pred_list.to_list()\n","    df_checkin['Predicted Number of Checkins'] = checkin_pred\n","\n","    print('Evaluate the predictions')\n","    checkout_true = df_predictions['Check-out True Values'].to_numpy()\n","    checkout_pred = df_predictions['Check-out Predictions'].to_numpy()\n","    checkin_true = df_checkin[['Number of Checkins']].to_numpy()\n","    checkin_pred = df_checkin[['Predicted Number of Checkins']].to_numpy()\n","\n","    print('Checkout evaluation:')\n","    checkout_mse, checkout_rmse, checkout_mre, checkout_mae = self.evaluate(checkout_true, checkout_pred)\n","    print('mse, rmse, mre, mae: ', checkout_mse, checkout_rmse, checkout_mre, checkout_mae)\n","    print('Checkin evaluation:')\n","    checkin_mse, checkin_rmse, checkin_mre, checkin_mae = self.evaluate(checkin_true, checkin_pred)\n","    print('mse, rmse, mre, mae: ', checkin_mse, checkin_rmse, checkin_mre, checkin_mae)\n","    # return checkout_mse, checkout_rmse, checkout_mre, checkout_mae, checkin_mse, checkin_rmse, checkin_mre, checkin_mae\n","    return checkout_test, checkin_test, df_transition_matrix, df_predictions, df_checkin, checkout_mse, checkout_rmse, checkout_mre, checkout_mae, checkin_mse, checkin_rmse, checkin_mre, checkin_mae"]},{"cell_type":"markdown","metadata":{"id":"lM94MGjrbSa1"},"source":["# 3. Run Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":316137,"status":"ok","timestamp":1648792244508,"user":{"displayName":"Nancy Li","userId":"12562624317552008542"},"user_tz":240},"id":"2MQ-dAFsRz2b","outputId":"91304238-eff7-4821-f253-558a17d3c55c"},"outputs":[{"output_type":"stream","name":"stdout","text":["(2438720, 26)\n","(2438720, 27)\n"]}],"source":["merged_bike_data_2019, df_weather = import_ridership_weather_data()"]},{"cell_type":"code","source":["def run_scenarios(df_checkout_errs, df_checkin_errs, n_transition_matrix_list, temperatureFlag_list):\n","  savepath_folder = '/content/drive/My Drive/MIE498 Thesis/Share-Bike-Station-Clustering-and-Usage-Prediction/prediction_results/'\n","  merged_data = merge_clustering_data(ridership_data=merged_bike_data_2019, weather_data=df_weather)\n","  checkout_data, checkin_data = filter_checkout_checkin_data(merged_data)\n","  for temperatureFlag in temperatureFlag_list:\n","    for n_transition_matrix in n_transition_matrix_list:\n","      print(temperatureFlag, n_transition_matrix)\n","      start_time = time.time()\n","      bikedemand = BikeDemand(nTransitions=n_transition_matrix, tempflag=temperatureFlag)\n","      checkout_test, checkin_test, df_transition_matrix, df_predictions, df_checkin, checkout_mse, checkout_rmse, checkout_mre, checkout_mae, checkin_mse, checkin_rmse, checkin_mre, checkin_mae = bikedemand.run_prediction_pipeline(merged_data, checkout_data, checkin_data)\n","      savepath_checkout = savepath_folder + 'CheckoutPred__nTMs={}_Temp={}_FSA.csv'.format(n_transition_matrix, temperatureFlag)\n","      savepath_checkin = savepath_folder + 'CheckinPred_nTMs={}_Temp={}_FSA.csv'.format(n_transition_matrix, temperatureFlag)\n","      # df_predictions.to_csv(savepath_checkout)\n","      # df_checkin.to_csv(savepath_checkin)\n","      print(\"Total Time Elapsed: \", time.time() - start_time)\n","\n","      # Save results\n","      df_temp = {'n Transition Matrix' : bikedemand.nTransitionMatrix, 'Temperature': bikedemand.tempFlag,'mse': checkout_mse, 'rmse': checkout_rmse, 'mre': checkout_mre, 'mae': checkout_mae}\n","      df_checkout_errs = df_checkout_errs.append(df_temp, ignore_index=True)\n","      df_temp = {'n Transition Matrix' : bikedemand.nTransitionMatrix, 'Temperature': bikedemand.tempFlag,'mse': checkin_mse, 'rmse': checkin_rmse, 'mre': checkin_mre, 'mae': checkin_mae}\n","      df_checkin_errs = df_checkin_errs.append(df_temp, ignore_index=True)\n","  savepath_checkout_errors = savepath_folder + 'CheckoutErrors_FSA.csv'\n","  savepath_checkin_errors = savepath_folder + 'CheckinErrors_FSA.csv'\n","  df_checkout_errs.to_csv(savepath_checkout_errors)\n","  df_checkin_errs.to_csv(savepath_checkin_errors)\n","  return df_checkout_errs, df_checkin_errs"],"metadata":{"id":"gmDdCM_QJ9M5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ROkITbKlh0o8"},"source":["## FSA"]},{"cell_type":"code","source":["n_transition_matrix_list = [1, 24, 48]\n","temperatureFlag_list = [True, False]\n","df_checkout_errs = pd.DataFrame(columns = ['n Transition Matrix', 'Temperature', 'mse', 'rmse', 'mre', 'mae'])\n","df_checkin_errs = pd.DataFrame(columns = ['n Transition Matrix', 'Temperature', 'mse', 'rmse', 'mre', 'mae'])\n","df_checkout_errs, df_checkin_errs = run_scenarios(df_checkout_errs, df_checkin_errs, n_transition_matrix_list, temperatureFlag_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t2rQeoY4KNge","outputId":"94b49b6a-1035-4ae8-f153-979edf2b6e36","executionInfo":{"status":"ok","timestamp":1648794919970,"user_tz":240,"elapsed":803323,"user":{"displayName":"Nancy Li","userId":"12562624317552008542"}}},"execution_count":24,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  if __name__ == '__main__':\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["True 1\n","38\n","Checkout predictions\n","(2438720, 16) (1970776, 16) (467944, 16)\n","number of missing combinations: 51\n","number of missing combinations: 144\n","Train Data Shape:  (142379, 6)\n","Test Data Shape:  (47281, 6)\n","Checkout training and testing errors\n","training errors:  235.78 15.355 270.696 6.628\n","testing errors:  143.77 11.99 188.765 5.331\n","Transition Matrix Computation\n","(2438720, 33) (1970776, 33) (467944, 33)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:268: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Summarize checkout predictions\n","0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:276: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["5000\n","10000\n","15000\n","20000\n","25000\n","30000\n","35000\n","40000\n","45000\n","Checkin predictions\n","(2438720, 15) (1970751, 15) (467969, 15)\n","number of missing combinations: 40\n","number of missing combinations: 149\n","Train Data Shape:  (138828, 6)\n","Test Data Shape:  (46104, 6)\n","Evaluate the predictions\n","Checkout evaluation:\n","mse, rmse, mre, mae:  143.77 11.99 188.765 5.331\n","Checkin evaluation:\n","mse, rmse, mre, mae:  84.229 9.178 253.519 3.311\n","Total Time Elapsed:  300.29579734802246\n","True 24\n","38\n","Checkout predictions\n","(2438720, 16) (1970776, 16) (467944, 16)\n","number of missing combinations: 51\n","number of missing combinations: 144\n","Train Data Shape:  (142379, 6)\n","Test Data Shape:  (47281, 6)\n","Checkout training and testing errors\n","training errors:  235.78 15.355 270.696 6.628\n","testing errors:  143.77 11.99 188.765 5.331\n","Transition Matrix Computation\n","(2438720, 33) (1970776, 33) (467944, 33)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:268: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Summarize checkout predictions\n","0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:276: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["5000\n","10000\n","15000\n","20000\n","25000\n","30000\n","35000\n","40000\n","45000\n","Checkin predictions\n","(2438720, 15) (1970751, 15) (467969, 15)\n","number of missing combinations: 40\n","number of missing combinations: 149\n","Train Data Shape:  (138828, 6)\n","Test Data Shape:  (46104, 6)\n","Evaluate the predictions\n","Checkout evaluation:\n","mse, rmse, mre, mae:  143.77 11.99 188.765 5.331\n","Checkin evaluation:\n","mse, rmse, mre, mae:  72.053 8.488 190.479 3.143\n","Total Time Elapsed:  295.4060003757477\n","True 48\n","38\n","Checkout predictions\n","(2438720, 16) (1970776, 16) (467944, 16)\n","number of missing combinations: 51\n","number of missing combinations: 144\n","Train Data Shape:  (142379, 6)\n","Test Data Shape:  (47281, 6)\n","Checkout training and testing errors\n","training errors:  235.78 15.355 270.696 6.628\n","testing errors:  143.77 11.99 188.765 5.331\n","Transition Matrix Computation\n","(2438720, 33) (1970776, 33) (467944, 33)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:268: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Summarize checkout predictions\n","0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:276: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["5000\n","10000\n","15000\n","20000\n","25000\n","30000\n","35000\n","40000\n","45000\n","Checkin predictions\n","(2438720, 15) (1970751, 15) (467969, 15)\n","number of missing combinations: 40\n","number of missing combinations: 149\n","Train Data Shape:  (138828, 6)\n","Test Data Shape:  (46104, 6)\n","Evaluate the predictions\n","Checkout evaluation:\n","mse, rmse, mre, mae:  143.77 11.99 188.765 5.331\n","Checkin evaluation:\n","mse, rmse, mre, mae:  70.005 8.367 187.23 3.113\n","Total Time Elapsed:  343.82294964790344\n","False 1\n","38\n","Checkout predictions\n","(2438720, 16) (1970776, 16) (467944, 16)\n","number of missing combinations: 51\n","number of missing combinations: 144\n","Train Data Shape:  (142379, 5)\n","Test Data Shape:  (47281, 5)\n","Checkout training and testing errors\n","training errors:  394.487 19.862 326.087 9.071\n","testing errors:  146.967 12.123 193.056 5.842\n","Transition Matrix Computation\n","(2438720, 33) (1970776, 33) (467944, 33)\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:268: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Summarize checkout predictions\n","0\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:276: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["5000\n","10000\n","15000\n","20000\n","25000\n","30000\n","35000\n","40000\n","45000\n","Checkin predictions\n","(2438720, 15) (1970751, 15) (467969, 15)\n","number of missing combinations: 40\n","number of missing combinations: 149\n","Train Data Shape:  (138826, 5)\n","Test Data Shape:  (46104, 5)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:299: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"]},{"output_type":"stream","name":"stdout","text":["Evaluate the predictions\n","Checkout evaluation:\n","mse, rmse, mre, mae:  146.967 12.123 193.056 5.842\n","Checkin evaluation:\n","mse, rmse, mre, mae:  93.122 9.65 270.21 3.919\n","Total Time Elapsed:  333.9346523284912\n","False 24\n","38\n","Checkout predictions\n","(2438720, 16) (1970776, 16) (467944, 16)\n","number of missing combinations: 51\n","number of missing combinations: 144\n","Train Data Shape:  (142379, 5)\n","Test Data Shape:  (47281, 5)\n","Checkout training and testing errors\n","training errors:  394.487 19.862 326.087 9.071\n","testing errors:  146.967 12.123 193.056 5.842\n","Transition Matrix Computation\n","(2438720, 33) (1970776, 33) (467944, 33)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:268: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"output_type":"stream","name":"stdout","text":["Summarize checkout predictions\n","0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:276: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"output_type":"stream","name":"stdout","text":["5000\n","10000\n","15000\n","20000\n","25000\n","30000\n","35000\n","40000\n","45000\n","Checkin predictions\n","(2438720, 15) (1970751, 15) (467969, 15)\n","number of missing combinations: 40\n","number of missing combinations: 149\n","Train Data Shape:  (138826, 5)\n","Test Data Shape:  (46104, 5)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:299: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"]},{"output_type":"stream","name":"stdout","text":["Evaluate the predictions\n","Checkout evaluation:\n","mse, rmse, mre, mae:  146.967 12.123 193.056 5.842\n","Checkin evaluation:\n","mse, rmse, mre, mae:  82.735 9.096 227.381 3.763\n","Total Time Elapsed:  332.9720935821533\n","False 48\n","38\n","Checkout predictions\n","(2438720, 16) (1970776, 16) (467944, 16)\n","number of missing combinations: 51\n","number of missing combinations: 144\n","Train Data Shape:  (142379, 5)\n","Test Data Shape:  (47281, 5)\n","Checkout training and testing errors\n","training errors:  394.487 19.862 326.087 9.071\n","testing errors:  146.967 12.123 193.056 5.842\n","Transition Matrix Computation\n","(2438720, 33) (1970776, 33) (467944, 33)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:268: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"output_type":"stream","name":"stdout","text":["Summarize checkout predictions\n","0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:276: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"output_type":"stream","name":"stdout","text":["5000\n","10000\n","15000\n","20000\n","25000\n","30000\n","35000\n","40000\n","45000\n","Checkin predictions\n","(2438720, 15) (1970751, 15) (467969, 15)\n","number of missing combinations: 40\n","number of missing combinations: 149\n","Train Data Shape:  (138826, 5)\n","Test Data Shape:  (46104, 5)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:299: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"]},{"output_type":"stream","name":"stdout","text":["Evaluate the predictions\n","Checkout evaluation:\n","mse, rmse, mre, mae:  146.967 12.123 193.056 5.842\n","Checkin evaluation:\n","mse, rmse, mre, mae:  80.221 8.957 224.565 3.73\n","Total Time Elapsed:  348.08723044395447\n"]}]},{"cell_type":"code","execution_count":25,"metadata":{"id":"WwZoKVJWAR53","colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"status":"ok","timestamp":1648796652821,"user_tz":240,"elapsed":154,"user":{"displayName":"Nancy Li","userId":"12562624317552008542"}},"outputId":"169940c2-ef27-4b27-e0e8-1d3c01876104"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["  n Transition Matrix Temperature      mse    rmse      mre    mae\n","0                   1        True  143.770  11.990  188.765  5.331\n","1                  24        True  143.770  11.990  188.765  5.331\n","2                  48        True  143.770  11.990  188.765  5.331\n","3                   1       False  146.967  12.123  193.056  5.842\n","4                  24       False  146.967  12.123  193.056  5.842\n","5                  48       False  146.967  12.123  193.056  5.842"],"text/html":["\n","  <div id=\"df-df3c091d-f66f-443f-a041-cdcb3e02a9c4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>n Transition Matrix</th>\n","      <th>Temperature</th>\n","      <th>mse</th>\n","      <th>rmse</th>\n","      <th>mre</th>\n","      <th>mae</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>143.770</td>\n","      <td>11.990</td>\n","      <td>188.765</td>\n","      <td>5.331</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>24</td>\n","      <td>True</td>\n","      <td>143.770</td>\n","      <td>11.990</td>\n","      <td>188.765</td>\n","      <td>5.331</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>48</td>\n","      <td>True</td>\n","      <td>143.770</td>\n","      <td>11.990</td>\n","      <td>188.765</td>\n","      <td>5.331</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>146.967</td>\n","      <td>12.123</td>\n","      <td>193.056</td>\n","      <td>5.842</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>24</td>\n","      <td>False</td>\n","      <td>146.967</td>\n","      <td>12.123</td>\n","      <td>193.056</td>\n","      <td>5.842</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>48</td>\n","      <td>False</td>\n","      <td>146.967</td>\n","      <td>12.123</td>\n","      <td>193.056</td>\n","      <td>5.842</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df3c091d-f66f-443f-a041-cdcb3e02a9c4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-df3c091d-f66f-443f-a041-cdcb3e02a9c4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-df3c091d-f66f-443f-a041-cdcb3e02a9c4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":25}],"source":["df_checkout_errs"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"BcdAIjOm26Ab","colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"status":"ok","timestamp":1648796657260,"user_tz":240,"elapsed":163,"user":{"displayName":"Nancy Li","userId":"12562624317552008542"}},"outputId":"0121531b-9642-4e02-b04a-0862877685fe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["  n Transition Matrix Temperature     mse   rmse      mre    mae\n","0                   1        True  84.229  9.178  253.519  3.311\n","1                  24        True  72.053  8.488  190.479  3.143\n","2                  48        True  70.005  8.367  187.230  3.113\n","3                   1       False  93.122  9.650  270.210  3.919\n","4                  24       False  82.735  9.096  227.381  3.763\n","5                  48       False  80.221  8.957  224.565  3.730"],"text/html":["\n","  <div id=\"df-c05057d5-2fbe-4435-b9ec-d0d2888c49ec\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>n Transition Matrix</th>\n","      <th>Temperature</th>\n","      <th>mse</th>\n","      <th>rmse</th>\n","      <th>mre</th>\n","      <th>mae</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>True</td>\n","      <td>84.229</td>\n","      <td>9.178</td>\n","      <td>253.519</td>\n","      <td>3.311</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>24</td>\n","      <td>True</td>\n","      <td>72.053</td>\n","      <td>8.488</td>\n","      <td>190.479</td>\n","      <td>3.143</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>48</td>\n","      <td>True</td>\n","      <td>70.005</td>\n","      <td>8.367</td>\n","      <td>187.230</td>\n","      <td>3.113</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>93.122</td>\n","      <td>9.650</td>\n","      <td>270.210</td>\n","      <td>3.919</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>24</td>\n","      <td>False</td>\n","      <td>82.735</td>\n","      <td>9.096</td>\n","      <td>227.381</td>\n","      <td>3.763</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>48</td>\n","      <td>False</td>\n","      <td>80.221</td>\n","      <td>8.957</td>\n","      <td>224.565</td>\n","      <td>3.730</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c05057d5-2fbe-4435-b9ec-d0d2888c49ec')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c05057d5-2fbe-4435-b9ec-d0d2888c49ec button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c05057d5-2fbe-4435-b9ec-d0d2888c49ec');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":26}],"source":["df_checkin_errs"]},{"cell_type":"markdown","source":["around 3.5 hours for each k2 (~20 minutes for transition matrix = [1,24,48])"],"metadata":{"id":"ngGb8p3FRAy4"}}],"metadata":{"colab":{"collapsed_sections":[],"name":"Checkout_Checkin_Predictions_FSA.ipynb","provenance":[],"authorship_tag":"ABX9TyMwiLKZGZOml3B2LNNeAjq+"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}